{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a41dfe",
   "metadata": {},
   "source": [
    "<h1>Pose Detection Implemented with mediaPipe and Opencv<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df397e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Libraries\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b9af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare  Some Variables\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "ROOTPATH  =  working_dir =os.path.join(os.getcwd(),'Poses') #Path to the folder with images  Poses folder contains images \n",
    "IMAGEEXTENTION = ('.jpg', '.png', 'jpeg','JPG','.webp') #Declaare valid image extensions\n",
    "WIDTH = 900 #Set width value\n",
    "HEIGHT = 600 #Set height value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01320748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Body Landmarks Detection.  \n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cefcc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_files is dictionary data structure, key = pose title  value = pose image storage address\n",
    "#Full_List is dictionary data structure contains output results \n",
    "def ExtractPointsandSaveinCSV(image_files, Full_List):\n",
    "    \n",
    "    for keys, b in image_files.items():\n",
    "        \n",
    "        with mp_holistic.Holistic(\n",
    "            static_image_mode=True,\n",
    "            model_complexity=2,\n",
    "            enable_segmentation=True,\n",
    "            refine_face_landmarks=True) as holistic:\n",
    "            \n",
    "            image = cv2.imread(b)\n",
    "            image = cv2.resize(image, (WIDTH,HEIGHT), interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "            results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            if results.pose_landmarks:\n",
    "                \n",
    "                a = {11 : 11, 12 : 12,\n",
    "                     13 : 13, 14 : 14,\n",
    "                     15 : 15, 16 : 16,\n",
    "                     23 : 23, 24 : 24,\n",
    "                     25 : 25, 26 : 26,\n",
    "                     27 : 27, 28 : 28}\n",
    "                \n",
    "                for i in (a.keys()):\n",
    "                    key = a[i]\n",
    "                    cordinates = []\n",
    "                    X = int(np.round(results.pose_landmarks.landmark[key].x * WIDTH))\n",
    "                    Y = int(np.round(results.pose_landmarks.landmark[key].y * HEIGHT))\n",
    "                    cordinates.append(X)\n",
    "                    cordinates.append(Y)\n",
    "                    a[i] = cordinates\n",
    "                Full_List[keys] = a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "715d7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw body landmarks \n",
    "\n",
    "def restore_landmarks(pose_map, image, color, thickness, color_circle = (255,0,0), radious = 10, text = ' '):\n",
    "    \n",
    "    for indx, pose in enumerate(pose_map.keys()):\n",
    "        cv2.circle(image, pose_map[pose], radious, color_circle, -thickness)\n",
    "        if pose == 11:\n",
    "            cv2.line(image, pose_map[pose], pose_map[13], color, thickness)\n",
    "            cv2.line(image, pose_map[pose], pose_map[23], color, thickness)\n",
    "            cv2.line(image, pose_map[pose], pose_map[12], color, thickness)\n",
    "        elif pose == 12:\n",
    "            cv2.line(image, pose_map[pose], pose_map[14], color, thickness)\n",
    "            cv2.line(image, pose_map[pose], pose_map[24], color, thickness)\n",
    "        elif pose == 13:\n",
    "            cv2.line(image, pose_map[pose], pose_map[15], color, thickness)\n",
    "        elif pose == 14:\n",
    "            cv2.line(image, pose_map[pose], pose_map[16], color, thickness)\n",
    "        elif pose == 23:\n",
    "            cv2.line(image, pose_map[pose], pose_map[25], color, thickness)\n",
    "            cv2.line(image, pose_map[pose], pose_map[24], color, thickness)\n",
    "        elif pose == 24:\n",
    "            cv2.line(image, pose_map[pose], pose_map[26], color, thickness)\n",
    "        elif pose == 25:\n",
    "            cv2.line(image, pose_map[pose], pose_map[27], color, thickness)\n",
    "        elif pose == 26:\n",
    "            cv2.line(image, pose_map[pose], pose_map[28], color, thickness)\n",
    "        position = (10,50)\n",
    "        cv2.putText(image,text,position, cv2.FONT_HERSHEY_SIMPLEX, 2,(209, 80, 0, 255),2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c28440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate accurance of user Pose and Standart Pose \n",
    "def calculate_accurancy(standart_pose, user_pose):\n",
    "    accurancy = {}\n",
    "    standart_list = list(standart_pose.items())\n",
    "    user_list = list(user_pose.items())\n",
    "    for i in range(len(standart_pose)):\n",
    "        point=standart_list[i][0]\n",
    "        standart = standart_list[i][1]\n",
    "        value = user_list[i][1]\n",
    "        absolute = [abs(standart[0]-value[0]),abs(standart[1]-value[1])]\n",
    "        try:\n",
    "            a = absolute[0]/value[0]\n",
    "            b = absolute[1]/value[1]\n",
    "        except ZeroDivisionError:\n",
    "            a = value[0]\n",
    "            b = value[1]\n",
    "        relative = [round((a*100),1),round((b*100),1)]\n",
    "        accurancy[point]=relative\n",
    "    return accurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e87c194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_landmarks(results):\n",
    "    a= results.pose_landmarks\n",
    "    landmark_map = {11 : 11, 12 : 12,\n",
    "                    13 : 13, 14 : 14,\n",
    "                    15 : 15, 16 : 16,\n",
    "                    23 : 23, 24 : 24,\n",
    "                    25 : 25, 26 : 26,\n",
    "                    27 : 27, 28 : 28}\n",
    "    \n",
    "\n",
    "    for i in (landmark_map.keys()):\n",
    "        key = landmark_map[i]\n",
    "        cordinates = []\n",
    "        X = int(np.round(results.pose_landmarks.landmark[key].x * WIDTH))\n",
    "        Y = int(np.round(results.pose_landmarks.landmark[key].y * HEIGHT))\n",
    "        cordinates.append(X)\n",
    "        cordinates.append(Y)\n",
    "        landmark_map[i] = cordinates\n",
    "    return landmark_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b169b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageList(poseList):\n",
    "    for indx, file_name in enumerate(os.listdir(ROOTPATH)):\n",
    "        if file_name.endswith(IMAGEEXTENTION):\n",
    "            file_path=os.path.join(ROOTPATH, file_name)\n",
    "            poseList[file_name[0:(file_name.rfind('.'))]]=file_path\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1345d76c",
   "metadata": {},
   "source": [
    "<h1>DEMONSTRATION</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1671894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "poseList= {}\n",
    "imageMarks = {}\n",
    "getImageList(poseList)\n",
    "ExtractPointsandSaveinCSV(poseList, imageMarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f38300e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example with static images \n",
    "for key, val in imageMarks.items():\n",
    "    Pose = imageMarks[key]\n",
    "    \n",
    "    frame = np.zeros((HEIGHT, WIDTH, 3), dtype = \"uint8\")\n",
    "    restore_landmarks(Pose, frame, (255,0,0), 1, (0,255,0), 5, str(key)) #RGB(255,0,0) line color RGB(0,255,0) circle color \n",
    "    cv2.imshow((str(key)), frame) \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69474547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example with videostream\n",
    "for key, val in imageMarks.items():\n",
    "    Pose = imageMarks[key]\n",
    "    vid = cv2.VideoCapture(0)\n",
    "    while(True):\n",
    "        ret, frame = vid.read()\n",
    "        frame = cv2.resize(frame, (WIDTH, HEIGHT), interpolation= cv2.INTER_LINEAR)\n",
    "        frame = cv2.flip(frame,1)\n",
    "        restore_landmarks(Pose,frame,(255,0,0),5)\n",
    "        cv2.imshow(str(key), frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): #press q to exit loop\n",
    "            break\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8147e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfb5882f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n",
      "Not Matched\n"
     ]
    }
   ],
   "source": [
    "#Real time pose detection with calculations \n",
    "#If match line green \n",
    "Pose = imageMarks['WarriorPose']\n",
    "\n",
    "\n",
    "for key, val in imageMarks.items():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    Pose = imageMarks[key]\n",
    "    with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                continue\n",
    "          \n",
    "            image = cv2.resize(image, (WIDTH,HEIGHT), interpolation= cv2.INTER_LINEAR)\n",
    "            image = cv2.flip(image,1)\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = holistic.process(image)\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    results.pose_landmarks,\n",
    "                    mp_holistic.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                restore_landmarks(Pose,image,(255,0,0),10)\n",
    "                user_pose = save_landmarks(results)\n",
    "                results = calculate_accurancy(Pose, user_pose)\n",
    "                results_list = list(results.items())\n",
    "                for i in range(len(results)):\n",
    "                    a = results_list[i][1]\n",
    "                    if a[0] > 0.5 and a[1] > 0.5:\n",
    "                        print(\"Not Matched\")\n",
    "                        break\n",
    "                    else:\n",
    "                        restore_landmarks(Pose,image,(0,255,0),10, (0,255,0), 10, text = 'Matched')\n",
    "                        print(\"Matched\")\n",
    "            cv2.imshow('MediaPipe Holistic', image)\n",
    "            if cv2.waitKey(5) & 0xFF == 27: #Press Esc to exit \n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8d88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
